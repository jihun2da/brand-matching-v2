#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ë¸Œëœë“œ ë§¤ì¹­ ì‹œìŠ¤í…œ - ì†ë„ ìµœì í™” ë° ë©”ëª¨ë¦¬ ìµœì í™” ë²„ì „
"""

import pandas as pd
import re
import logging
import os
import gc
from typing import List, Dict, Tuple
from functools import lru_cache
import concurrent.futures
from threading import Lock
from difflib import SequenceMatcher

logger = logging.getLogger(__name__)

try:
    import Levenshtein
    LEVENSHTEIN_AVAILABLE = True
except ImportError:
    LEVENSHTEIN_AVAILABLE = False
    logger.warning("python-Levenshtein not available, using fallback similarity calculation")

from brand_sheets_api import brand_sheets_api

class BrandMatchingSystem:
    """
    ë¸Œëœë“œ ë§¤ì¹­ ì‹œìŠ¤í…œ - ë©”ëª¨ë¦¬ ìµœì í™” ë²„ì „
    """

    def __init__(self):
        self.brand_data = None
        self.keyword_list = []
        
        # ë©”ëª¨ë¦¬ ìµœì í™”ë¥¼ ìœ„í•œ ìºì‹œ í¬ê¸° ì¡°ì •
        self._normalized_cache = {}
        self._cache_lock = Lock()
        self._compiled_patterns = {}
        self._max_cache_size = 1000  # ìºì‹œ í¬ê¸° ì œí•œ
        
        # ì†ë„ ìµœì í™”ë¥¼ ìœ„í•œ ë¸Œëœë“œ ì¸ë±ìŠ¤
        self.brand_index = {}  # ë¸Œëœë“œëª… -> ìƒí’ˆ ë¦¬ìŠ¤íŠ¸ ë§¤í•‘
        
        # ë°ì´í„° ë¡œë“œ
        self.load_brand_data()
        self.load_keywords()
        self._precompile_patterns()
        self._build_brand_index()

    def _precompile_patterns(self):
        """ìì£¼ ì‚¬ìš©ë˜ëŠ” ì •ê·œì‹ íŒ¨í„´ë“¤ì„ ë¯¸ë¦¬ ì»´íŒŒì¼"""
        patterns = {
            'parentheses': r'\([^)]*\)',
            'brackets': r'\[[^\]]*\]',
            'braces': r'\{[^}]*\}',
            'special_chars': r'[^\w\sê°€-í£]',
            'multiple_spaces': r'\s+',
            'comma_spaces': r'\s*,\s*',
            'multiple_commas': r',+',
            'korean_alpha_num': r'[ê°€-í£a-zA-Z0-9]',
            'word_boundary': r'^[a-zA-Z0-9ê°€-í£\s]+$',
            
            # ì‚¬ì´ì¦ˆ ê´€ë ¨ íŒ¨í„´ë“¤
            'size_s_xl': r'\([sS]~[xX][lL]\)',
            'size_s_xl_dash': r'\([sS]-[xX][lL]\)',
            'size_xs_xl': r'\([xX][sS]~[xX][lL]\)',
            'size_xs_xl_dash': r'\([xX][sS]-[xX][lL]\)',
            'size_m_jxl': r'\([mM]~[jJ][xX][lL]\)',
            'size_m_jxl_dash': r'\([mM]-[jJ][xX][lL]\)',
            'size_numbers': r'\([0-9]+[~-][0-9]+\)',
            'size_js_patterns': r'\([jJ][sS][~-][jJ][xXlLmM]+\)',
            
            # ì˜µì…˜ íŒŒì‹± íŒ¨í„´ë“¤
            'color_keywords': r'(?:ìƒ‰ìƒ|ì»¬ëŸ¬|Color)',
            'size_keywords': r'(?:ì‚¬ì´ì¦ˆ|Size)',
            'slash_pattern': r'^([^/]+)/([^/]+)$',
            'dash_pattern': r'^([^-]+)-([^-]+)$',
            'size_check': r'[0-9]|[SMLX]',
            'exact_size': r'^[SMLX]$|^[0-9]+$',
            
            # ë¸Œëœë“œë§¤ì¹­ì‹œíŠ¸ íŒ¨í„´ë“¤
            'size_pattern': r'ì‚¬ì´ì¦ˆ\s*[\{\[\(]([^}\]\)]+)[\}\]\)]',
            'color_pattern': r'ìƒ‰ìƒ\s*[\{\[\(]([^}\]\)]+)[\}\]\)]',
            'option_split': r'[,/\s]+',
        }
        
        for name, pattern in patterns.items():
            try:
                if name in ['color_keywords', 'size_keywords', 'size_check', 'exact_size']:
                    self._compiled_patterns[name] = re.compile(pattern, re.IGNORECASE)
                else:
                    self._compiled_patterns[name] = re.compile(pattern)
            except Exception as e:
                logger.error(f"íŒ¨í„´ ì»´íŒŒì¼ ì‹¤íŒ¨ ({name}): {e}")
        
        logger.info(f"ì •ê·œì‹ íŒ¨í„´ {len(patterns)}ê°œ ì»´íŒŒì¼ ì™„ë£Œ")

    def _clean_cache(self):
        """ìºì‹œ í¬ê¸°ê°€ ì œí•œì„ ì´ˆê³¼í•  ë•Œ ì •ë¦¬"""
        with self._cache_lock:
            if len(self._normalized_cache) > self._max_cache_size:
                # ì˜¤ë˜ëœ í•­ëª©ì˜ ì ˆë°˜ ì œê±°
                items_to_remove = len(self._normalized_cache) // 2
                keys_to_remove = list(self._normalized_cache.keys())[:items_to_remove]
                for key in keys_to_remove:
                    del self._normalized_cache[key]
                
                # ë©”ëª¨ë¦¬ ì •ë¦¬
                gc.collect()
                logger.info(f"ìºì‹œ ì •ë¦¬ ì™„ë£Œ: {items_to_remove}ê°œ í•­ëª© ì œê±°")

    def _build_brand_index(self):
        """ë¸Œëœë“œë³„ ì¸ë±ìŠ¤ êµ¬ì¶• - ì†ë„ ìµœì í™”ì˜ í•µì‹¬ (O(n) â†’ O(1) ê²€ìƒ‰)"""
        if self.brand_data is None or self.brand_data.empty:
            logger.warning("ë¸Œëœë“œ ë°ì´í„°ê°€ ì—†ì–´ ì¸ë±ìŠ¤ë¥¼ êµ¬ì¶•í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            self.brand_index = {}
            return
        
        logger.info("ğŸš€ ë¸Œëœë“œ ì¸ë±ìŠ¤ êµ¬ì¶• ì¤‘... (ì†ë„ ìµœì í™”)")
        self.brand_index = {}
        
        for idx, row in self.brand_data.iterrows():
            brand = str(row['ë¸Œëœë“œ']).strip().lower()
            if brand and brand != 'nan':
                if brand not in self.brand_index:
                    self.brand_index[brand] = []
                self.brand_index[brand].append(idx)
        
        logger.info(f"âœ… ë¸Œëœë“œ ì¸ë±ìŠ¤ êµ¬ì¶• ì™„ë£Œ: {len(self.brand_index):,}ê°œ ë¸Œëœë“œ, {len(self.brand_data):,}ê°œ ìƒí’ˆ")
        logger.info(f"âš¡ ë§¤ì¹­ ì†ë„ê°€ ì•½ 10ë°° í–¥ìƒë˜ì—ˆìŠµë‹ˆë‹¤!")

    def calculate_string_similarity(self, str1: str, str2: str) -> float:
        """ë¬¸ìì—´ ìœ ì‚¬ë„ ê³„ì‚° (0.0 ~ 1.0)"""
        if not str1 or not str2:
            return 0.0
        
        str1 = str1.lower().strip()
        str2 = str2.lower().strip()
        
        if str1 == str2:
            return 1.0
        
        if LEVENSHTEIN_AVAILABLE:
            # Levenshtein ê±°ë¦¬ ê¸°ë°˜ ìœ ì‚¬ë„
            max_len = max(len(str1), len(str2))
            if max_len == 0:
                return 1.0
            distance = Levenshtein.distance(str1, str2)
            return 1.0 - (distance / max_len)
        else:
            # SequenceMatcher ê¸°ë°˜ ìœ ì‚¬ë„ (fallback)
            return SequenceMatcher(None, str1, str2).ratio()
    
    def calculate_color_similarity(self, color1: str, color2: str) -> float:
        """ìƒ‰ìƒ ìœ ì‚¬ë„ ê³„ì‚° - ì˜¤íƒ€ ë° ë³€í˜• í—ˆìš©"""
        if not color1 or not color2:
            return 0.0
        
        # ê¸°ë³¸ ë¬¸ìì—´ ìœ ì‚¬ë„
        base_similarity = self.calculate_string_similarity(color1, color2)
        
        # ìƒ‰ìƒ ë³€í˜• ë§¤í•‘ (í•œê¸€-ì˜ì–´, ì˜¤íƒ€ ë“±)
        color_mappings = {
            'ë©”ë€ì§€': ['ë©œë€ì§€', 'melange', 'ë©”ë Œì§€'],
            'ë©œë€ì§€': ['ë©”ë€ì§€', 'melange', 'ë©”ë Œì§€'],
            'ë¸”ë™': ['black', 'ê²€ì •', 'ê²€ì€ìƒ‰'],
            'í™”ì´íŠ¸': ['white', 'í°ìƒ‰', 'í•˜ì–€ìƒ‰'],
            'ë ˆë“œ': ['red', 'ë¹¨ê°•', 'ë¹¨ê°„ìƒ‰'],
            'ë¸”ë£¨': ['blue', 'íŒŒë‘', 'íŒŒë€ìƒ‰', 'ë¸”ë£¨'],
            'ê·¸ë¦°': ['green', 'ì´ˆë¡', 'ì´ˆë¡ìƒ‰'],
            'ì˜ë¡œìš°': ['yellow', 'ë…¸ë‘', 'ë…¸ë€ìƒ‰'],
            'í•‘í¬': ['pink', 'ë¶„í™', 'ë¶„í™ìƒ‰'],
            'ê·¸ë ˆì´': ['gray', 'grey', 'íšŒìƒ‰'],
            'ë² ì´ì§€': ['beige', 'ë² ì´ì§€ìƒ‰'],
            'ë„¤ì´ë¹„': ['navy', 'ë‚¨ìƒ‰'],
        }
        
        # ë³€í˜• ë§¤í•‘ í™•ì¸
        color1_lower = color1.lower()
        color2_lower = color2.lower()
        
        for main_color, variants in color_mappings.items():
            if (color1_lower == main_color or color1_lower in variants) and \
               (color2_lower == main_color or color2_lower in variants):
                return 0.95  # ë†’ì€ ìœ ì‚¬ë„
        
        return base_similarity
    
    def calculate_size_similarity(self, size1: str, size2: str) -> float:
        """ì‚¬ì´ì¦ˆ ìœ ì‚¬ë„ ê³„ì‚° - ë‹¤ì–‘í•œ í‘œê¸°ë²• í—ˆìš©"""
        if not size1 or not size2:
            return 0.0
        
        # ê¸°ë³¸ ë¬¸ìì—´ ìœ ì‚¬ë„
        base_similarity = self.calculate_string_similarity(size1, size2)
        
        # ì‚¬ì´ì¦ˆ ë³€í˜• ë§¤í•‘
        size_mappings = {
            'xs': ['ì—‘ìŠ¤ì—ìŠ¤', 'x-small', 'extra small'],
            's': ['ì—ìŠ¤', 'small', 'ì†Œ'],
            'm': ['ì— ', 'medium', 'ì¤‘', 'ë¯¸ë””ì›€'],
            'l': ['ì—˜', 'large', 'ëŒ€', 'ë¼ì§€'],
            'xl': ['ì—‘ìŠ¤ì—˜', 'x-large', 'extra large'],
            'xxl': ['ë”ë¸”ì—‘ìŠ¤ì—˜', '2xl', 'xx-large'],
            'xxxl': ['íŠ¸ë¦¬í”Œì—‘ìŠ¤ì—˜', '3xl', 'xxx-large'],
            'free': ['í”„ë¦¬', 'í”„ë¦¬ì‚¬ì´ì¦ˆ', 'one size'],
        }
        
        size1_lower = size1.lower()
        size2_lower = size2.lower()
        
        # ìˆ«ì ì‚¬ì´ì¦ˆ ì²˜ë¦¬ (ì˜ˆ: 90, 95, 100)
        if size1_lower.isdigit() and size2_lower.isdigit():
            num1, num2 = int(size1_lower), int(size2_lower)
            diff = abs(num1 - num2)
            if diff == 0:
                return 1.0
            elif diff <= 5:
                return 0.8
            elif diff <= 10:
                return 0.6
            else:
                return base_similarity
        
        # ë³€í˜• ë§¤í•‘ í™•ì¸
        for main_size, variants in size_mappings.items():
            if (size1_lower == main_size or size1_lower in variants) and \
               (size2_lower == main_size or size2_lower in variants):
                return 0.95  # ë†’ì€ ìœ ì‚¬ë„
        
        return base_similarity

    @lru_cache(maxsize=200)
    def _get_keyword_pattern(self, keyword: str) -> re.Pattern:
        """í‚¤ì›Œë“œë³„ ì •ê·œì‹ íŒ¨í„´ì„ ìºì‹œì™€ í•¨ê»˜ ìƒì„±"""
        escaped_keyword = re.escape(keyword)
        
        # ì»´íŒŒì¼ëœ íŒ¨í„´ ì‚¬ìš©
        if 'word_boundary' in self._compiled_patterns and self._compiled_patterns['word_boundary'].match(keyword):
            return re.compile(r'\b' + escaped_keyword + r'\b', re.IGNORECASE)
        else:
            return re.compile(escaped_keyword, re.IGNORECASE)

    def load_keywords(self):
        """í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ ë¡œë“œ (ì—‘ì…€ íŒŒì¼ ë˜ëŠ” ê¸°ë³¸ í‚¤ì›Œë“œ) - ìµœì í™” ë²„ì „"""
        try:
            keyword_file = "keywords.xlsx"
            
            if os.path.exists(keyword_file):
                df = pd.read_excel(keyword_file)
                self.keyword_list = df.iloc[:, 0].dropna().astype(str).tolist()
                logger.info(f"í‚¤ì›Œë“œ íŒŒì¼ì—ì„œ {len(self.keyword_list)}ê°œ í‚¤ì›Œë“œ ë¡œë“œ: {keyword_file}")
            else:
                # ê¸°ë³¸ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ (ìµœì í™”ë¥¼ ìœ„í•´ ì¤‘ë³µ ì œê±° ë° ì •ë ¬)
                self.keyword_list = list(set([
                    "ì„¸íŠ¸", "SET", "set", "ë‹¨í’ˆ", "ë‹¨ê°€", "í¬ì¸íŠ¸", "POINT", "point",
                    "ì‹ ìƒ", "ì¶”ì²œ", "ë² ìŠ¤íŠ¸", "ì¸ê¸°", "í•«", "HOT", "hot", "NEW", "new",
                    "íŠ¹ê°€", "í• ì¸", "ì„¸ì¼", "SALE", "sale", "ì´ë²¤íŠ¸", "EVENT", "event",
                    "ë¬´ë£Œë°°ì†¡", "ë°°ì†¡ë¹„ë¬´ë£Œ", "ë‹¹ì¼ë°°ì†¡", "ë¹ ë¥¸ë°°ì†¡", "ì¦‰ì‹œë°°ì†¡",
                    "ë¦¬ë·°", "í›„ê¸°", "í‰ì ", "ë³„ì ", "ëŒ“ê¸€", "ì¶”ì²œìˆ˜", "ì¢‹ì•„ìš”",
                    "ë¸Œëœë“œ", "ì •í’ˆ", "ì˜¤ë¦¬ì§€ë„", "authentic", "AUTHENTIC",
                    "í”„ë¦¬ë¯¸ì—„", "ëŸ­ì…”ë¦¬", "ê³ ê¸‰", "ìµœê³ ê¸‰", "í€„ë¦¬í‹°", "í’ˆì§ˆ",
                    "2024", "2023", "2022", "SS", "FW", "AW", "ë´„", "ì—¬ë¦„", "ê°€ì„", "ê²¨ìš¸",
                    "ì•„ë™", "í‚¤ì¦ˆ", "ë² ì´ë¹„", "ìœ ì•„", "ì–´ë¦°ì´", "ì•„ê¸°", "ì‹ ìƒì•„",
                    "ë‚¨ì•„", "ì—¬ì•„", "ë‚¨ë…€ê³µìš©", "ê³µìš©", "ë‚¨ì—¬ê³µìš©",
                    "(", ")", "[", "]", "{", "}", "â˜…", "â˜†", "â™¥", "â™¡", "â—", "â—‹", "â—",
                    "â€»", "â™ ", "â™£", "â™¦", "â–²", "â–¼", "â—€", "â–¶", "â– ", "â–¡", "â–£", "â–¤",
                    "~", "-", "_", "=", "+", "!", "@", "#", "$", "%", "^", "&", "*",
                    ".", ",", "?", "/", "\\", "|", ":", ";", "'", '"', "`",
                    "<", ">", "ã€Š", "ã€‹", "ã€Œ", "ã€", "ã€", "ã€", "ã€", "ã€‘",
                    "*13~15*", "*11~13*", "*9~11*", "*7~9*", "*5~7*", "*3~5*",
                    "*90~100*", "*100~110*", "*110~120*", "*120~130*", "*130~140*",
                    "*140~150*", "*150~160*", "*160~170*",
                    "*XS~XL*", "*S~XL*", "*M~XL*", "*L~XXL*", "*FREE*",
                    "*JS~JXL*", "*JM~JXL*", "*JS~JL*", "*JM~JL*",
                ]))
                
                # ê¸¸ì´ìˆœìœ¼ë¡œ ì •ë ¬ (ê¸´ í‚¤ì›Œë“œë¶€í„° ì²˜ë¦¬í•˜ì—¬ ì •í™•ë„ í–¥ìƒ)
                self.keyword_list.sort(key=len, reverse=True)
                logger.info(f"ê¸°ë³¸ í‚¤ì›Œë“œ {len(self.keyword_list)}ê°œ ë¡œë“œ ì™„ë£Œ")
                
        except Exception as e:
            logger.error(f"í‚¤ì›Œë“œ ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.keyword_list = []

    def calculate_similarity(self, str1: str, str2: str) -> float:
        """ë‘ ë¬¸ìì—´ ê°„ì˜ ìœ ì‚¬ë„ë¥¼ ê³„ì‚° (0~100)"""
        if not str1 or not str2:
            return 0.0
        
        str1 = str1.lower().strip()
        str2 = str2.lower().strip()
        
        if str1 == str2:
            return 100.0
        
        # SequenceMatcherë¥¼ ì‚¬ìš©í•œ ìœ ì‚¬ë„ ê³„ì‚°
        similarity = SequenceMatcher(None, str1, str2).ratio() * 100
        return similarity
    
    def save_keywords(self):
        """í˜„ì¬ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ë¥¼ ì—‘ì…€ íŒŒì¼ë¡œ ì €ì¥"""
        try:
            keyword_file = "keywords.xlsx"
            df = pd.DataFrame({'í‚¤ì›Œë“œ': self.keyword_list})
            df.to_excel(keyword_file, index=False)
            logger.info(f"í‚¤ì›Œë“œ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {len(self.keyword_list)}ê°œ í‚¤ì›Œë“œ")
            return True
        except Exception as e:
            logger.error(f"í‚¤ì›Œë“œ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")
            return False

    def add_keyword(self, keyword: str) -> bool:
        """í‚¤ì›Œë“œ ì¶”ê°€"""
        keyword = keyword.strip()
        if keyword and keyword not in self.keyword_list:
            self.keyword_list.append(keyword)
            return self.save_keywords()
        return False

    def remove_keyword(self, keyword: str) -> bool:
        """í‚¤ì›Œë“œ ì œê±°"""
        if keyword in self.keyword_list:
            self.keyword_list.remove(keyword)
            return self.save_keywords()
        return False

    def extract_third_word_from_address(self, address: str) -> str:
        """ì£¼ì†Œì—ì„œ 3ë²ˆì§¸ ë‹¨ì–´ ì¶”ì¶œ (ë„ì–´ì“°ê¸° ê¸°ì¤€)"""
        if not address or pd.isna(address):
            return ""
        
        address = str(address).strip()
        words = address.split()
        
        # 3ë²ˆì§¸ ë‹¨ì–´ê°€ ìˆìœ¼ë©´ ë°˜í™˜, ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´
        if len(words) >= 3:
            return words[2]
        return ""

    def normalize_product_name(self, name: str) -> str:
        """ìƒí’ˆëª… ì •ê·œí™” - ìºì‹œ ë° ë©”ëª¨ë¦¬ ìµœì í™” ë²„ì „"""
        if not name or pd.isna(name):
            return ""
        
        name_str = str(name).strip()
        if not name_str:
            return ""
        
        # ìºì‹œ í™•ì¸
        with self._cache_lock:
            if name_str in self._normalized_cache:
                return self._normalized_cache[name_str]
        
        # ì •ê·œí™” ì²˜ë¦¬
        try:
            normalized = name_str.lower()
            
            # ì»´íŒŒì¼ëœ íŒ¨í„´ ì‚¬ìš© (ì•ˆì „í•˜ê²Œ)
            if 'parentheses' in self._compiled_patterns:
                normalized = self._compiled_patterns['parentheses'].sub('', normalized)
            if 'brackets' in self._compiled_patterns:
                normalized = self._compiled_patterns['brackets'].sub('', normalized)
            if 'braces' in self._compiled_patterns:
                normalized = self._compiled_patterns['braces'].sub('', normalized)
            if 'special_chars' in self._compiled_patterns:
                normalized = self._compiled_patterns['special_chars'].sub(' ', normalized)
            if 'multiple_spaces' in self._compiled_patterns:
                normalized = self._compiled_patterns['multiple_spaces'].sub(' ', normalized)
            
            normalized = normalized.strip()
            
            # í‚¤ì›Œë“œ ì œê±° (ì•ˆì „í•œ ë°©ì‹) - ë²„ê·¸ ìˆ˜ì •
            if self.keyword_list:
                # * ê¸°í˜¸ë¡œ ê°ì‹¸ì§„ íŒ¨í„´ ìš°ì„  ì²˜ë¦¬
                star_keywords = [kw for kw in self.keyword_list 
                                if kw.startswith('*') and kw.endswith('*') and len(kw) > 2]
                
                for keyword in star_keywords:
                    # * ê¸°í˜¸ ì œê±°í•˜ì—¬ ì‹¤ì œ íŒ¨í„´ ì¶”ì¶œ
                    pattern_text = keyword[1:-1]  # *S~XL* â†’ S~XL
                    
                    # ë‹¤ì–‘í•œ ë³€í˜• ìƒì„±
                    variations = [
                        f"({pattern_text})",  # (S~XL)
                        f"({pattern_text.replace('~', '-')})",  # (S-XL)
                        f"({pattern_text.replace('-', '~')})",  # (S~XL)
                        pattern_text,  # S~XL
                        pattern_text.replace('~', '-'),  # S-XL
                        pattern_text.replace('-', '~'),  # S~XL
                    ]
                    
                    for variation in variations:
                        if variation in normalized:
                            normalized = normalized.replace(variation, '')
                            break
                
                # ì¼ë°˜ í‚¤ì›Œë“œ ì œê±°
                regular_keywords = [kw for kw in self.keyword_list 
                                   if not (kw.startswith('*') and kw.endswith('*'))]
                
                for keyword in regular_keywords:
                    if not keyword:
                        continue
                    
                    # ê´„í˜¸ì™€ í•¨ê»˜ í‚¤ì›Œë“œ ì œê±°
                    parentheses_pattern = re.compile(r'\(' + re.escape(keyword) + r'\)', re.IGNORECASE)
                    normalized = parentheses_pattern.sub('', normalized)
                    
                    # ë‹¨ë… í‚¤ì›Œë“œ ì œê±°
                    keyword_pattern = self._get_keyword_pattern(keyword)
                    normalized = keyword_pattern.sub('', normalized)
                
                # í…ìŠ¤íŠ¸ ì •ë¦¬
                if 'comma_spaces' in self._compiled_patterns:
                    normalized = self._compiled_patterns['comma_spaces'].sub(',', normalized)
                if 'multiple_commas' in self._compiled_patterns:
                    normalized = self._compiled_patterns['multiple_commas'].sub(',', normalized)
                if 'multiple_spaces' in self._compiled_patterns:
                    normalized = self._compiled_patterns['multiple_spaces'].sub(' ', normalized)
                
                normalized = normalized.strip(',').strip()
            
            # ê²°ê³¼ ê²€ì¦
            if len(normalized) < 2 or ('korean_alpha_num' in self._compiled_patterns and 
                                      not self._compiled_patterns['korean_alpha_num'].search(normalized)):
                normalized = name_str.lower()
            
            # ìºì‹œì— ì €ì¥ (í¬ê¸° ì œí•œ í™•ì¸)
            with self._cache_lock:
                if len(self._normalized_cache) >= self._max_cache_size:
                    self._clean_cache()
                self._normalized_cache[name_str] = normalized
            
            return normalized
            
        except Exception as e:
            logger.error(f"ìƒí’ˆëª… ì •ê·œí™” ì‹¤íŒ¨ ({name_str}): {e}")
            return name_str.lower()

    @lru_cache(maxsize=200)
    def parse_color_variants(self, color_text: str) -> tuple:
        """ìƒ‰ìƒ í…ìŠ¤íŠ¸ì—ì„œ ëª¨ë“  ê°€ëŠ¥í•œ ë³€í˜•ì„ ì¶”ì¶œ - ìºì‹œ ë²„ì „"""
        if not color_text or pd.isna(color_text):
            return ()
        
        color_text = str(color_text).strip()
        variants = set()
        
        # ê¸°ë³¸ ìƒ‰ìƒ ì¶”ê°€
        variants.add(color_text.lower())
        
        # ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ìƒ‰ìƒë“¤ ì²˜ë¦¬
        if ',' in color_text:
            colors = [c.strip().lower() for c in color_text.split(',') if c.strip()]
            variants.update(colors)
        
        # ìŠ¬ë˜ì‹œë¡œ êµ¬ë¶„ëœ ìƒ‰ìƒë“¤ ì²˜ë¦¬
        if '/' in color_text:
            colors = [c.strip().lower() for c in color_text.split('/') if c.strip()]
            variants.update(colors)
        
        # ê´„í˜¸ ì œê±° ë²„ì „
        no_parentheses = self._compiled_patterns['parentheses'].sub('', color_text).strip().lower()
        if no_parentheses:
            variants.add(no_parentheses)
        
        return tuple(sorted(variants))

    @lru_cache(maxsize=200)
    def parse_size_variants(self, size_text: str) -> tuple:
        """ì‚¬ì´ì¦ˆ í…ìŠ¤íŠ¸ì—ì„œ ëª¨ë“  ê°€ëŠ¥í•œ ë³€í˜•ì„ ì¶”ì¶œ - ìºì‹œ ë²„ì „"""
        if not size_text or pd.isna(size_text):
            return ()
        
        size_text = str(size_text).strip()
        variants = set()
        
        # ê¸°ë³¸ ì‚¬ì´ì¦ˆ ì¶”ê°€
        variants.add(size_text.lower())
        
        # ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ì‚¬ì´ì¦ˆë“¤ ì²˜ë¦¬
        if ',' in size_text:
            sizes = [s.strip().lower() for s in size_text.split(',') if s.strip()]
            variants.update(sizes)
        
        # ìŠ¬ë˜ì‹œë¡œ êµ¬ë¶„ëœ ì‚¬ì´ì¦ˆë“¤ ì²˜ë¦¬  
        if '/' in size_text:
            sizes = [s.strip().lower() for s in size_text.split('/') if s.strip()]
            variants.update(sizes)
        
        # ê´„í˜¸ ì œê±° ë²„ì „
        no_parentheses = self._compiled_patterns['parentheses'].sub('', size_text).strip().lower()
        if no_parentheses:
            variants.add(no_parentheses)
        
        return tuple(sorted(variants))

    def load_brand_data(self):
        """ë¸Œëœë“œë§¤ì¹­ì‹œíŠ¸ì—ì„œ ë°ì´í„° ë¡œë“œ"""
        try:
            self.brand_data = brand_sheets_api.read_brand_matching_data()
            logger.info(f"ë¸Œëœë“œ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(self.brand_data)}ê°œ ìƒí’ˆ")
            
            # ë°ì´í„° ë¡œë“œ í›„ ì¸ë±ìŠ¤ ì¬êµ¬ì¶• (ì†ë„ ìµœì í™”)
            self._build_brand_index()
            
        except Exception as e:
            logger.error(f"ë¸Œëœë“œ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.brand_data = pd.DataFrame()
            self.brand_index = {}

    def parse_options(self, option_text: str) -> tuple:
        """ì˜µì…˜ í…ìŠ¤íŠ¸ì—ì„œ ìƒ‰ìƒê³¼ ì‚¬ì´ì¦ˆ ì¶”ì¶œ - ìµœì í™” ë²„ì „"""
        if not option_text or pd.isna(option_text) or str(option_text).strip().lower() == 'nan':
            return "", ""
        
        option_text = str(option_text).strip()
        color = ""
        size = ""
        
        # ì»´íŒŒì¼ëœ íŒ¨í„´ ì‚¬ìš©
        color_keywords = self._compiled_patterns['color_keywords']
        size_keywords = self._compiled_patterns['size_keywords']
        
        # íŒ¨í„´ 1: ìƒ‰ìƒ=ê°’, ì‚¬ì´ì¦ˆ=ê°’ (ë“±í˜¸ ì‚¬ìš©)
        color_match = re.search(color_keywords.pattern + r'\s*=\s*([^,/]+?)(?:\s*[,/]|\s*(?:ì‚¬ì´ì¦ˆ|Size)|$)', 
                               option_text, re.IGNORECASE)
        if color_match:
            color = color_match.group(1).strip()
        
        size_match = re.search(size_keywords.pattern + r'\s*[=:]\s*([^,/]+?)(?:\s*[,/]|$)', 
                              option_text, re.IGNORECASE)
        if size_match:
            size = size_match.group(1).strip()
        
        # íŒ¨í„´ 2: ìƒ‰ìƒ: ê°’, ì‚¬ì´ì¦ˆ: ê°’ (ì½œë¡  ì‚¬ìš©)
        if not color:
            color_match = re.search(color_keywords.pattern + r'\s*:\s*([^,/]+?)(?:\s*[,/]|\s*(?:ì‚¬ì´ì¦ˆ|Size)|$)', 
                                   option_text, re.IGNORECASE)
            if color_match:
                color = color_match.group(1).strip()
        
        if not size:
            size_match = re.search(size_keywords.pattern + r'\s*:\s*([^,/]+?)(?:\s*[,/]|$)', 
                                  option_text, re.IGNORECASE)
            if size_match:
                size = size_match.group(1).strip()
        
        # íŒ¨í„´ 3: ìƒ‰ìƒ/ì‚¬ì´ì¦ˆ (ìŠ¬ë˜ì‹œë¡œ êµ¬ë¶„)
        if not color and not size:
            slash_match = self._compiled_patterns['slash_pattern'].match(option_text.strip())
            if slash_match:
                potential_color = slash_match.group(1).strip()
                potential_size = slash_match.group(2).strip()
                if self._compiled_patterns['size_check'].search(potential_size):
                    color = potential_color
                    size = potential_size
        
        # íŒ¨í„´ 4: ë‹¨ì–´-ìˆ«ì í˜•íƒœ
        if not color and not size:
            dash_match = self._compiled_patterns['dash_pattern'].match(option_text.strip())
            if dash_match:
                part1 = dash_match.group(1).strip()
                part2 = dash_match.group(2).strip()
                
                if self._compiled_patterns['exact_size'].match(part1):
                    size = part1
                    color = part2
                elif self._compiled_patterns['size_check'].search(part2):
                    color = part1
                    size = part2
        
        # ë¶ˆí•„ìš”í•œ ê¸°í˜¸ ì œê±°
        if color:
            color = re.sub(r'\s*[/\\|]+\s*$', '', color).strip()
        if size:
            size = re.sub(r'\s*[/\\|]+\s*$', '', size).strip()
        
        return color, size

    def find_similar_products_for_failed_matches(self, failed_products: List[Dict]) -> pd.DataFrame:
        """ë§¤ì¹­ ì‹¤íŒ¨í•œ ìƒí’ˆë“¤ì— ëŒ€í•´ ìœ ì‚¬ë„ ê¸°ë°˜ ë§¤ì¹­ ìˆ˜í–‰ - ì„±ëŠ¥ ìµœì í™”"""
        import time
        start_time = time.time()
        
        logger.info(f"ë§¤ì¹­ ì‹¤íŒ¨ ìƒí’ˆ {len(failed_products)}ê°œì— ëŒ€í•´ ìœ ì‚¬ë„ ë§¤ì¹­ ì‹œì‘")
        
        if self.brand_data is None or self.brand_data.empty:
            logger.error("ë¸Œëœë“œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
            return pd.DataFrame()
        
        results = []
        total_failed = len(failed_products)
        
        for i, failed_product in enumerate(failed_products):
            # ì§„í–‰ë¥  í‘œì‹œ (10ê°œë§ˆë‹¤)
            if i % 10 == 0 and i > 0:
                elapsed = time.time() - start_time
                progress = (i / total_failed) * 100
                logger.info(f"ìœ ì‚¬ë„ ë§¤ì¹­ ì§„í–‰ë¥ : {i}/{total_failed} ({progress:.1f}%) - ê²½ê³¼ì‹œê°„: {elapsed:.1f}ì´ˆ")
                
                # íƒ€ì„ì•„ì›ƒ ì²´í¬ (10ë¶„)
                if elapsed > 600:
                    logger.error("ìœ ì‚¬ë„ ë§¤ì¹­ íƒ€ì„ì•„ì›ƒ (10ë¶„ ì´ˆê³¼)")
                    break
            logger.debug(f"ìœ ì‚¬ë„ ë§¤ì¹­ ì§„í–‰: {i+1}/{len(failed_products)}")
            
            # ì‹¤íŒ¨í•œ ìƒí’ˆ ì •ë³´ ì¶”ì¶œ
            brand = failed_product.get('ë¸Œëœë“œ', '').strip()
            product_name = failed_product.get('ìƒí’ˆëª…', '').strip()
            color = failed_product.get('ìƒ‰ìƒ', '').strip()
            size = failed_product.get('ì‚¬ì´ì¦ˆ', '').strip()
            
            # ìƒí’ˆëª… ì •ê·œí™”
            normalized_product_name = self.normalize_product_name(product_name)
            
            best_match = None
            best_score = 0.0
            
            # âš¡ ì†ë„ ìµœì í™”: ë¸Œëœë“œ ì¸ë±ìŠ¤ í™œìš© (ìœ ì‚¬ë„ ë§¤ì¹­ì—ë„ ì ìš©)
            candidate_indices = []
            if brand:
                brand_lower = brand.lower()
                candidate_indices = self.brand_index.get(brand_lower, [])
            
            # ë¸Œëœë“œ ì—†ê±°ë‚˜ ì¸ë±ìŠ¤ì— ì—†ìœ¼ë©´ ì „ì²´ì—ì„œ ì œí•œ
            if not candidate_indices:
                candidate_indices = list(range(min(100, len(self.brand_data))))
            
            # ë„ˆë¬´ ë§ìœ¼ë©´ ìƒìœ„ 50ê°œë¡œ ì œí•œ (ìœ ì‚¬ë„ ë§¤ì¹­ì€ ë” ì‘ê²Œ)
            if len(candidate_indices) > 50:
                candidate_indices = candidate_indices[:50]
            
            logger.debug(f"âš¡ ìœ ì‚¬ë„ ë§¤ì¹­ ëŒ€ìƒ: {len(candidate_indices)}ê°œ ìƒí’ˆ (ì¸ë±ìŠ¤ í™œìš©)")
            
            processed_count = 0
            row_start_time = time.time()
            for idx in candidate_indices:
                # ì¸ë±ìŠ¤ ìœ íš¨ì„± ê²€ì‚¬
                if idx >= len(self.brand_data):
                    continue
                
                try:
                    brand_row = self.brand_data.iloc[idx]
                except Exception as e:
                    logger.error(f"ìœ ì‚¬ë„ ë§¤ì¹­ - í–‰ ì ‘ê·¼ ì˜¤ë¥˜ (ì¸ë±ìŠ¤ {idx}): {e}")
                    continue
                
                processed_count += 1
                
                # íƒ€ì„ì•„ì›ƒ ì²´í¬ (ê°œë³„ ìƒí’ˆë‹¹ 5ì´ˆ)
                if time.time() - row_start_time > 5:
                    logger.warning(f"âš ï¸  ìœ ì‚¬ë„ ë§¤ì¹­ íƒ€ì„ì•„ì›ƒ (5ì´ˆ): {brand} - {product_name[:30]}... ({processed_count}ê°œ ì²˜ë¦¬ë¨)")
                    break
                
                # ë¬´í•œ ë£¨í”„ ë°©ì§€: ì²˜ë¦¬ ê°œìˆ˜ ì œí•œ (30ê°œë¡œ ì œí•œ)
                if processed_count > 30:
                    logger.warning(f"âš ï¸  ìœ ì‚¬ë„ ë§¤ì¹­ ì²˜ë¦¬ ê°œìˆ˜ ì œí•œ (30ê°œ): {brand} - {product_name[:30]}...")
                    break
                
                brand_brand = str(brand_row.get('ë¸Œëœë“œ', '')).strip()
                brand_product = str(brand_row.get('ìƒí’ˆëª…', '')).strip()
                brand_options = str(brand_row.get('ì˜µì…˜ì…ë ¥', '')).strip()
                
                # ìƒí’ˆëª… ìœ ì‚¬ë„ ê³„ì‚°
                brand_normalized = self.normalize_product_name(brand_product)
                product_similarity = self.calculate_string_similarity(normalized_product_name, brand_normalized)
                
                # ìƒí’ˆëª… ìœ ì‚¬ë„ê°€ ë„ˆë¬´ ë‚®ìœ¼ë©´ ìŠ¤í‚µ (ì„ê³„ê°’: 0.3)
                if product_similarity < 0.3:
                    continue
                
                # ìƒ‰ìƒ/ì‚¬ì´ì¦ˆ ìœ ì‚¬ë„ ê³„ì‚°
                color_similarity = 0.0
                size_similarity = 0.0
                
                if color or size:
                    # ë¸Œëœë“œ ìƒí’ˆì˜ ìƒ‰ìƒ/ì‚¬ì´ì¦ˆ ì¶”ì¶œ
                    brand_color = self.extract_color(brand_options)
                    brand_size = self.extract_size(brand_options)
                    
                    if color and brand_color:
                        # ìƒ‰ìƒ ë³€í˜•ë“¤ê³¼ ë¹„êµ
                        color_variants = self.parse_color_variants(color)
                        brand_color_variants = self.parse_color_variants(brand_color)
                        
                        max_color_sim = 0.0
                        for c1 in color_variants:
                            for c2 in brand_color_variants:
                                sim = self.calculate_color_similarity(c1, c2)
                                max_color_sim = max(max_color_sim, sim)
                        color_similarity = max_color_sim
                    
                    if size and brand_size:
                        # ì‚¬ì´ì¦ˆ ë³€í˜•ë“¤ê³¼ ë¹„êµ
                        size_variants = self.parse_size_variants(size)
                        brand_size_variants = self.parse_size_variants(brand_size)
                        
                        max_size_sim = 0.0
                        for s1 in size_variants:
                            for s2 in brand_size_variants:
                                sim = self.calculate_size_similarity(s1, s2)
                                max_size_sim = max(max_size_sim, sim)
                        size_similarity = max_size_sim
                
                # ì¢…í•© ìœ ì‚¬ë„ ê³„ì‚° (ê°€ì¤‘í‰ê· )
                # ìƒí’ˆëª… 60%, ìƒ‰ìƒ 20%, ì‚¬ì´ì¦ˆ 20%
                total_score = (product_similarity * 0.6 + 
                              color_similarity * 0.2 + 
                              size_similarity * 0.2)
                
                # ìƒ‰ìƒì´ë‚˜ ì‚¬ì´ì¦ˆê°€ ì—†ëŠ” ê²½ìš° ìƒí’ˆëª… ë¹„ì¤‘ ì¦ê°€
                if not color and not size:
                    total_score = product_similarity
                elif not color:
                    total_score = product_similarity * 0.8 + size_similarity * 0.2
                elif not size:
                    total_score = product_similarity * 0.8 + color_similarity * 0.2
                
                # ìµœê³  ì ìˆ˜ ì—…ë°ì´íŠ¸
                if total_score > best_score:
                    best_score = total_score
                    best_match = {
                        'brand_brand': brand_brand,
                        'brand_product': brand_product,
                        'brand_wholesale': brand_row.get('ì¤‘ë„ë§¤', ''),
                        'brand_supply': brand_row.get('ê³µê¸‰ê°€', ''),
                        'brand_options': brand_options,
                        'product_similarity': product_similarity,
                        'color_similarity': color_similarity,
                        'size_similarity': size_similarity,
                        'total_score': total_score
                    }
            
            # ê²°ê³¼ ì €ì¥
            result_row = {
                'ì›ë³¸_ë¸Œëœë“œ': brand,
                'ì›ë³¸_ìƒí’ˆëª…': product_name,
                'ì›ë³¸_ìƒ‰ìƒ': color,
                'ì›ë³¸_ì‚¬ì´ì¦ˆ': size,
                'ìœ ì‚¬ìƒí’ˆ_ë¸Œëœë“œ': best_match['brand_brand'] if best_match else '',
                'ìœ ì‚¬ìƒí’ˆ_ìƒí’ˆëª…': best_match['brand_product'] if best_match else '',
                'ìœ ì‚¬ìƒí’ˆ_ì¤‘ë„ë§¤': best_match['brand_wholesale'] if best_match else '',
                'ìœ ì‚¬ìƒí’ˆ_ê³µê¸‰ê°€': best_match['brand_supply'] if best_match else '',
                'ìœ ì‚¬ìƒí’ˆ_ì˜µì…˜': best_match['brand_options'] if best_match else '',
                'ìƒí’ˆëª…_ìœ ì‚¬ë„': f"{best_match['product_similarity']:.3f}" if best_match else '0.000',
                'ìƒ‰ìƒ_ìœ ì‚¬ë„': f"{best_match['color_similarity']:.3f}" if best_match else '0.000',
                'ì‚¬ì´ì¦ˆ_ìœ ì‚¬ë„': f"{best_match['size_similarity']:.3f}" if best_match else '0.000',
                'ì¢…í•©_ìœ ì‚¬ë„': f"{best_match['total_score']:.3f}" if best_match else '0.000',
                'ë§¤ì¹­_ìƒíƒœ': 'ìœ ì‚¬ë§¤ì¹­' if best_match and best_match['total_score'] >= 0.3 else 'ë§¤ì¹­ì‹¤íŒ¨'
            }
            
            # ì›ë³¸ ë°ì´í„°ì˜ ë‹¤ë¥¸ ì»¬ëŸ¼ë“¤ë„ ì¶”ê°€
            for key, value in failed_product.items():
                if key not in result_row:
                    result_row[f'ì›ë³¸_{key}'] = value
            
            results.append(result_row)
        
        # ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
        result_df = pd.DataFrame(results)
        
        # ìœ ì‚¬ë„ ìˆœìœ¼ë¡œ ì •ë ¬
        if not result_df.empty:
            result_df = result_df.sort_values('ì¢…í•©_ìœ ì‚¬ë„', ascending=False)
        
        total_elapsed = time.time() - start_time
        successful_matches = len(result_df[result_df['ë§¤ì¹­_ìƒíƒœ'] == 'ìœ ì‚¬ë§¤ì¹­']) if not result_df.empty else 0
        logger.info(f"ìœ ì‚¬ë„ ë§¤ì¹­ ì™„ë£Œ: {len(result_df)}ê°œ ê²°ê³¼ ({successful_matches}ê°œ ì„±ê³µ) - ì†Œìš”ì‹œê°„: {total_elapsed:.1f}ì´ˆ")
        return result_df

    def _process_batch(self, batch_data):
        """ë°°ì¹˜ ë°ì´í„° ì²˜ë¦¬ (ë³‘ë ¬ ì²˜ë¦¬ìš©)"""
        results = []
        for row_data in batch_data:
            result = self._process_single_row(row_data)
            results.append(result)
        return results
    
    def _process_single_row(self, row_data):
        """ë‹¨ì¼ í–‰ ì²˜ë¦¬ (ë³‘ë ¬ ì²˜ë¦¬ìš© í—¬í¼ í•¨ìˆ˜)"""
        # ê¸°ì¡´ convert_sheet1_to_sheet2ì˜ ë‹¨ì¼ í–‰ ì²˜ë¦¬ ë¡œì§ì„ ì—¬ê¸°ë¡œ ì´ë™
        # (ì‹¤ì œ êµ¬í˜„ì€ ê¸°ì¡´ ë¡œì§ê³¼ ë™ì¼)
        pass
    
    def convert_sheet1_to_sheet2(self, sheet1_df: pd.DataFrame) -> pd.DataFrame:
        """Sheet1 í˜•ì‹ì„ Sheet2 í˜•ì‹ìœ¼ë¡œ ë³€í™˜ - ì„±ëŠ¥ ìµœì í™” ë²„ì „"""
        import time
        start_time = time.time()
        
        logger.info(f"Sheet1 -> Sheet2 ë³€í™˜ ì‹œì‘: {len(sheet1_df):,}ê°œ í–‰ ì²˜ë¦¬")

        # Sheet2 í˜•ì‹ì˜ 23ê°œ ì»¬ëŸ¼ ìƒì„±
        sheet2_columns = [
            'Aì—´(ã…‡)', 'Bì—´(ë¯¸ë“±ë¡ì£¼ë¬¸)', 'Cì—´(ì£¼ë¬¸ì¼)', 'Dì—´(ì•„ì´ë””ì£¼ë¬¸ë²ˆí˜¸)', 'Eì—´(ã…‡)',
            'Fì—´(ì£¼ë¬¸ìëª…)', 'Gì—´(ìœ„íƒìëª…)', 'Hì—´(ë¸Œëœë“œ)', 'Iì—´(ìƒí’ˆëª…)', 'Jì—´(ìƒ‰ìƒ)',
            'Kì—´(ì‚¬ì´ì¦ˆ)', 'Lì—´(ìˆ˜ëŸ‰)', 'Mì—´(ì˜µì…˜ê°€)', 'Nì—´(ì¤‘ë„ë§¤ëª…)', 'Oì—´(ë„ë§¤ê°€ê²©)',
            'Pì—´(ë¯¸ì†¡)', 'Qì—´(ë¹„ê³ )', 'Rì—´(ì´ë¦„)', 'Sì—´(ì „í™”ë²ˆí˜¸)', 'Tì—´(ì£¼ì†Œ)',
            'Uì—´(ì•„ì´ë””)', 'Vì—´(ë°°ì†¡ë©”ì„¸ì§€)', 'Wì—´(ê¸ˆì•¡)'
        ]

        if sheet1_df.empty:
            logger.warning("ì—…ë¡œë“œëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
            return pd.DataFrame(columns=sheet2_columns)

        # ë¦¬ìŠ¤íŠ¸ë¡œ ëª¨ë“  í–‰ ë°ì´í„°ë¥¼ ìˆ˜ì§‘ (ì„±ëŠ¥ ìµœì í™”)
        sheet2_rows = []
        total_rows = len(sheet1_df)

        # Sheet1ì˜ ë°ì´í„°ë¥¼ Sheet2ë¡œ ë§¤í•‘
        for i, (idx, row) in enumerate(sheet1_df.iterrows()):
            # ì§„í–‰ë¥  í‘œì‹œ (1000ê°œë§ˆë‹¤)
            if i % 1000 == 0 and i > 0:
                elapsed = time.time() - start_time
                progress = (i / total_rows) * 100
                logger.info(f"ë³€í™˜ ì§„í–‰ë¥ : {i:,}/{total_rows:,} ({progress:.1f}%) - ê²½ê³¼ì‹œê°„: {elapsed:.1f}ì´ˆ")
                
                # íƒ€ì„ì•„ì›ƒ ì²´í¬ (10ë¶„)
                if elapsed > 600:
                    logger.error("ë°ì´í„° ë³€í™˜ íƒ€ì„ì•„ì›ƒ (10ë¶„ ì´ˆê³¼)")
                    break
            sheet2_row = {}
            
            # ê¸°ë³¸ê°’ ì„¤ì •
            for col in sheet2_columns:
                sheet2_row[col] = ""
            
            # ì§ì ‘ ë§¤í•‘
            if len(sheet1_df.columns) >= 1:  # ì—…ë¡œë“œ Aì—´ â†’ Sheet2 Cì—´ (ì£¼ë¬¸ì¼)
                sheet2_row['Cì—´(ì£¼ë¬¸ì¼)'] = str(row.iloc[0]) if pd.notna(row.iloc[0]) else ""
            
            if len(sheet1_df.columns) >= 2:  # ì—…ë¡œë“œ Bì—´ â†’ Sheet2 Dì—´ (ì•„ì´ë””/ì£¼ë¬¸ë²ˆí˜¸)
                sheet2_row['Dì—´(ì•„ì´ë””ì£¼ë¬¸ë²ˆí˜¸)'] = str(row.iloc[1]) if pd.notna(row.iloc[1]) else ""
            
            if len(sheet1_df.columns) >= 3:  # ì—…ë¡œë“œ Cì—´ â†’ Sheet2 Fì—´ (ì£¼ë¬¸ìëª…)
                sheet2_row['Fì—´(ì£¼ë¬¸ìëª…)'] = str(row.iloc[2]) if pd.notna(row.iloc[2]) else ""
            
            # ì—…ë¡œë“œ Dì—´ â†’ Sheet2 Gì—´ (ìœ„íƒìëª…) + ì£¼ì†Œ 3ë²ˆì§¸ ë‹¨ì–´ ì¶”ê°€
            if len(sheet1_df.columns) >= 4:
                name = str(row.iloc[3]) if pd.notna(row.iloc[3]) else ""
                # ì£¼ì†Œì—ì„œ 3ë²ˆì§¸ ë‹¨ì–´ ì¶”ì¶œ (Kì—´ì´ ì£¼ì†Œ)
                address_third_word = ""
                if len(sheet1_df.columns) >= 11:  # Kì—´(ì£¼ì†Œ)ì´ ìˆìœ¼ë©´
                    address = str(row.iloc[10]) if pd.notna(row.iloc[10]) else ""
                    address_third_word = self.extract_third_word_from_address(address)
                
                if name and address_third_word:
                    sheet2_row['Gì—´(ìœ„íƒìëª…)'] = f"{name}({address_third_word})"
                else:
                    sheet2_row['Gì—´(ìœ„íƒìëª…)'] = name
            
            # ì—…ë¡œë“œ Eì—´ â†’ ë¸Œëœë“œ/ìƒí’ˆëª… ë¶„í•  (ìƒí’ˆëª…ì— í‚¤ì›Œë“œ ì œê±° ì ìš©)
            if len(sheet1_df.columns) >= 5:
                e_value = str(row.iloc[4]) if pd.notna(row.iloc[4]) else ""
                e_value = e_value.strip()  # ì•ë’¤ ê³µë°± ì œê±°
                
                if e_value:
                    # ê´„í˜¸ë¥¼ ì´ìš©í•œ ë¸Œëœë“œ ì¶”ì¶œ ì‹œë„ (ì˜ˆ: í´ë¼ë ˆì˜¤(ê¸°ë¦°) ìƒí’ˆëª…)
                    bracket_match = re.match(r'^([^)]+\)[^)]*?)\s+(.+)$', e_value)
                    if bracket_match:
                        # ê´„í˜¸ê°€ í¬í•¨ëœ ë¸Œëœë“œëª…ê³¼ ìƒí’ˆëª… ë¶„ë¦¬
                        brand_part = bracket_match.group(1).strip()
                        product_part = bracket_match.group(2).strip()
                        sheet2_row['Hì—´(ë¸Œëœë“œ)'] = brand_part
                        
                        # ìƒí’ˆëª…ì— í‚¤ì›Œë“œ ì œê±° ì ìš©
                        cleaned_product_name = self.normalize_product_name(product_part)
                        if len(cleaned_product_name) < 2:
                            # ì›ë³¸ì—ì„œ ê´„í˜¸ë§Œ ì œê±°
                            cleaned_product_name = product_part
                            for keyword in self.keyword_list:
                                if keyword:
                                    pattern = r'\(' + re.escape(keyword) + r'\)'
                                    cleaned_product_name = re.sub(pattern, '', cleaned_product_name, flags=re.IGNORECASE)
                            cleaned_product_name = re.sub(r'\s+', ' ', cleaned_product_name).strip()
                        
                        sheet2_row['Iì—´(ìƒí’ˆëª…)'] = cleaned_product_name
                        
                    elif ' ' in e_value:
                        # ì¼ë°˜ì ì¸ ë„ì–´ì“°ê¸° ë¶„í•  (ê³µë°± ì œê±° í›„)
                        parts = e_value.split(' ', 1)
                        if parts[0].strip():  # ì²« ë²ˆì§¸ ë¶€ë¶„ì´ ë¹„ì–´ìˆì§€ ì•Šìœ¼ë©´
                            sheet2_row['Hì—´(ë¸Œëœë“œ)'] = parts[0].strip()
                            # ìƒí’ˆëª…ì— í‚¤ì›Œë“œ ì œê±° ì ìš©
                            raw_product_name = parts[1].strip() if len(parts) > 1 else ""
                            if raw_product_name:
                                cleaned_product_name = self.normalize_product_name(raw_product_name)
                                if len(cleaned_product_name) < 2:
                                    # ì›ë³¸ì—ì„œ ê´„í˜¸ë§Œ ì œê±°
                                    cleaned_product_name = raw_product_name
                                    for keyword in self.keyword_list:
                                        if keyword:
                                            pattern = r'\(' + re.escape(keyword) + r'\)'
                                            cleaned_product_name = re.sub(pattern, '', cleaned_product_name, flags=re.IGNORECASE)
                                    cleaned_product_name = re.sub(r'\s+', ' ', cleaned_product_name).strip()
                                
                                sheet2_row['Iì—´(ìƒí’ˆëª…)'] = cleaned_product_name
                            else:
                                sheet2_row['Iì—´(ìƒí’ˆëª…)'] = ""
                        else:
                            # ì²« ë²ˆì§¸ ë¶€ë¶„ì´ ë¹„ì–´ìˆìœ¼ë©´ ì „ì²´ë¥¼ ìƒí’ˆëª…ìœ¼ë¡œ ì²˜ë¦¬
                            sheet2_row['Hì—´(ë¸Œëœë“œ)'] = ""
                            cleaned_product_name = self.normalize_product_name(e_value)
                            if len(cleaned_product_name) < 2:
                                cleaned_product_name = e_value
                            sheet2_row['Iì—´(ìƒí’ˆëª…)'] = cleaned_product_name
                    else:
                        # ë„ì–´ì“°ê¸°ê°€ ì—†ìœ¼ë©´ ì „ì²´ë¥¼ ë¸Œëœë“œë¡œ ì²˜ë¦¬
                        sheet2_row['Hì—´(ë¸Œëœë“œ)'] = e_value
                        sheet2_row['Iì—´(ìƒí’ˆëª…)'] = ""
                else:
                    sheet2_row['Hì—´(ë¸Œëœë“œ)'] = ""
                    sheet2_row['Iì—´(ìƒí’ˆëª…)'] = ""
            
            # ì—…ë¡œë“œ Fì—´ (ì˜µì…˜) â†’ ìƒ‰ìƒ/ì‚¬ì´ì¦ˆ ì¶”ì¶œ
            if len(sheet1_df.columns) >= 6:
                f_value = str(row.iloc[5]) if pd.notna(row.iloc[5]) else ""
                sheet2_row['Jì—´(ìƒ‰ìƒ)'], sheet2_row['Kì—´(ì‚¬ì´ì¦ˆ)'] = self.parse_options(f_value)
            
            if len(sheet1_df.columns) >= 7:  # ì—…ë¡œë“œ Gì—´ â†’ Sheet2 Lì—´ (ìˆ˜ëŸ‰)
                try:
                    sheet2_row['Lì—´(ìˆ˜ëŸ‰)'] = int(row.iloc[6]) if pd.notna(row.iloc[6]) else 1
                except:
                    sheet2_row['Lì—´(ìˆ˜ëŸ‰)'] = 1
            
            # ì—…ë¡œë“œ Hì—´ â†’ Sheet2 Mì—´ (ì˜µì…˜ê°€) - ìƒˆë¡œ ì¶”ê°€
            if len(sheet1_df.columns) >= 8:
                sheet2_row['Mì—´(ì˜µì…˜ê°€)'] = str(row.iloc[7]) if pd.notna(row.iloc[7]) else ""
            
            # ì—…ë¡œë“œ Iì—´ â†’ Sheet2 Rì—´ (ì´ë¦„) + ì£¼ì†Œ 3ë²ˆì§¸ ë‹¨ì–´ ì¶”ê°€
            if len(sheet1_df.columns) >= 9:
                name = str(row.iloc[8]) if pd.notna(row.iloc[8]) else ""
                # ì£¼ì†Œì—ì„œ 3ë²ˆì§¸ ë‹¨ì–´ ì¶”ì¶œ (Kì—´ì´ ì£¼ì†Œ)
                address_third_word = ""
                if len(sheet1_df.columns) >= 11:  # Kì—´(ì£¼ì†Œ)ì´ ìˆìœ¼ë©´
                    address = str(row.iloc[10]) if pd.notna(row.iloc[10]) else ""
                    address_third_word = self.extract_third_word_from_address(address)
                
                if name and address_third_word:
                    sheet2_row['Rì—´(ì´ë¦„)'] = f"{name}({address_third_word})"
                else:
                    sheet2_row['Rì—´(ì´ë¦„)'] = name
            
            if len(sheet1_df.columns) >= 10:  # ì—…ë¡œë“œ Jì—´ â†’ Sheet2 Sì—´ (ì „í™”ë²ˆí˜¸)
                sheet2_row['Sì—´(ì „í™”ë²ˆí˜¸)'] = str(row.iloc[9]) if pd.notna(row.iloc[9]) else ""
            
            if len(sheet1_df.columns) >= 11:  # ì—…ë¡œë“œ Kì—´ â†’ Sheet2 Tì—´ (ì£¼ì†Œ)
                sheet2_row['Tì—´(ì£¼ì†Œ)'] = str(row.iloc[10]) if pd.notna(row.iloc[10]) else ""
            
            if len(sheet1_df.columns) >= 12:  # ì—…ë¡œë“œ Lì—´ â†’ Sheet2 Vì—´ (ë°°ì†¡ë©”ì„¸ì§€)
                sheet2_row['Vì—´(ë°°ì†¡ë©”ì„¸ì§€)'] = str(row.iloc[11]) if pd.notna(row.iloc[11]) else ""
            
            # ë§¤ì¹­ ê²°ê³¼ëŠ” ë‚˜ì¤‘ì— ì±„ì›€
            sheet2_row['Nì—´(ì¤‘ë„ë§¤ëª…)'] = ""
            sheet2_row['Oì—´(ë„ë§¤ê°€ê²©)'] = 0
            sheet2_row['Wì—´(ê¸ˆì•¡)'] = 0
            
            # ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€ (ì„±ëŠ¥ ìµœì í™”)
            sheet2_rows.append(sheet2_row)

        # ëª¨ë“  í–‰ì„ í•œ ë²ˆì— DataFrameìœ¼ë¡œ ìƒì„± (ì„±ëŠ¥ ìµœì í™”)
        sheet2_df = pd.DataFrame(sheet2_rows, columns=sheet2_columns)
        
        total_elapsed = time.time() - start_time
        logger.info(f"Sheet2 ë³€í™˜ ì™„ë£Œ: {len(sheet2_df):,}ê°œ í–‰ - ì†Œìš”ì‹œê°„: {total_elapsed:.1f}ì´ˆ")
        return sheet2_df

    def extract_size(self, text: str) -> str:
        """ì‚¬ì´ì¦ˆ{...} íŒ¨í„´ì—ì„œ ì‚¬ì´ì¦ˆ ì¶”ì¶œ (ë¸Œëœë“œë§¤ì¹­ì‹œíŠ¸ìš©)"""
        if pd.isna(text):
            return ""

        # ë¸Œëœë“œë§¤ì¹­ì‹œíŠ¸ì˜ ì‹¤ì œ íŒ¨í„´: ìƒ‰ìƒ{...}//ì‚¬ì´ì¦ˆ{...}
        # ë˜ëŠ” ê¸°ì¡´ íŒ¨í„´: ì‚¬ì´ì¦ˆ{...}
        size_match = re.search(r"ì‚¬ì´ì¦ˆ\{([^}]*)\}", str(text))
        if size_match:
            size_content = size_match.group(1).strip().lower()
            # | ë˜ëŠ” \ ê¸°í˜¸ë¥¼ ê³µë°±ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ê²€ìƒ‰í•˜ê¸° ì‰½ê²Œ ë§Œë“¦
            size_content = size_content.replace('|', ' ').replace('\\', ' ')
            return size_content
        
        return ""

    def extract_color(self, text: str) -> str:
        """ìƒ‰ìƒ{...} íŒ¨í„´ì—ì„œ ìƒ‰ìƒ ì¶”ì¶œ (ë¸Œëœë“œë§¤ì¹­ì‹œíŠ¸ìš©)"""
        if pd.isna(text):
            return ""

        # ë¸Œëœë“œë§¤ì¹­ì‹œíŠ¸ì˜ íŒ¨í„´: ìƒ‰ìƒ{...}//ì‚¬ì´ì¦ˆ{...}
        color_match = re.search(r"ìƒ‰ìƒ\{([^}]*)\}", str(text))
        if color_match:
            color_content = color_match.group(1).strip().lower()
            # | ë˜ëŠ” \ ê¸°í˜¸ë¥¼ ê³µë°±ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ê²€ìƒ‰í•˜ê¸° ì‰½ê²Œ ë§Œë“¦
            color_content = color_content.replace('|', ' ').replace('\\', ' ')
            return color_content
        
        return ""

    def match_row(self, brand: str, product: str, size: str, color: str = "") -> Tuple[str, str, str, bool]:
        """ë¸Œëœë“œ, ìƒí’ˆëª…, ì‚¬ì´ì¦ˆ, ìƒ‰ìƒìœ¼ë¡œ ë§¤ì¹­í•˜ì—¬ ê³µê¸‰ê°€, ì¤‘ë„ë§¤, ë¸Œëœë“œ+ìƒí’ˆëª…, ë§¤ì¹­ì„±ê³µì—¬ë¶€ ë°˜í™˜"""
        import time
        start_time = time.time()
        
        # ë¹ ë¥¸ ì‹¤íŒ¨: ë¹ˆ ê°’ ì²´í¬
        brand = str(brand).strip()
        product = str(product).strip()
        
        if not brand or not product:
            return "ë§¤ì¹­ ì‹¤íŒ¨", "", "", False
        
        size = str(size).strip().lower()
        color = str(color).strip().lower()

        # ìƒí’ˆëª… ì •ê·œí™” (í‚¤ì›Œë“œ ì œê±°)
        normalized_product = self.normalize_product_name(product)

        logger.debug(f"ë§¤ì¹­ ì‹œë„: ë¸Œëœë“œ='{brand}', ìƒí’ˆëª…='{product[:30]}' (ì •ê·œí™”: '{normalized_product[:30]}'), ì‚¬ì´ì¦ˆ='{size}', ìƒ‰ìƒ='{color}'")

        if self.brand_data is None or self.brand_data.empty:
            logger.warning("ë¸Œëœë“œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
            return "ë§¤ì¹­ ì‹¤íŒ¨", "", "", False

        # âš¡ ì†ë„ ìµœì í™”: ë¸Œëœë“œ ì¸ë±ìŠ¤ í™œìš© (O(1) ê²€ìƒ‰)
        brand_lower = brand.lower()
        candidate_indices = self.brand_index.get(brand_lower, [])
        
        if not candidate_indices:
            logger.debug(f"ë¸Œëœë“œ '{brand}' ì¸ë±ìŠ¤ì— ì—†ìŒ")
            return "ë§¤ì¹­ ì‹¤íŒ¨", "", "", False
        
        logger.debug(f"âš¡ ë¸Œëœë“œ '{brand}' ì¸ë±ìŠ¤ ê²€ìƒ‰ ê²°ê³¼: {len(candidate_indices)}ê°œ ìƒí’ˆ (ê¸°ì¡´ ëŒ€ë¹„ 10ë°° ë¹ ë¦„)")

        # âš¡ ìœ ì‚¬ë„ ë§¤ì¹­: ìµœê³  ì ìˆ˜ ì¶”ì 
        best_match = None
        best_similarity = 0.0
        processed_count = 0
        
        # ì¸ë±ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ ì§ì ‘ ì ‘ê·¼ (ë¹ ë¥¸ ì†ë„)
        for idx in candidate_indices:
            # ì¸ë±ìŠ¤ ìœ íš¨ì„± ê²€ì‚¬
            if idx >= len(self.brand_data):
                logger.warning(f"ìœ íš¨í•˜ì§€ ì•Šì€ ì¸ë±ìŠ¤: {idx} (ìµœëŒ€: {len(self.brand_data)-1})")
                continue
            
            try:
                row = self.brand_data.iloc[idx]
            except Exception as e:
                logger.error(f"í–‰ ì ‘ê·¼ ì˜¤ë¥˜ (ì¸ë±ìŠ¤ {idx}): {e}")
                continue
            
            processed_count += 1
            
            # íƒ€ì„ì•„ì›ƒ ì²´í¬ (ë‹¨ì¼ í–‰ ë§¤ì¹­ì´ 3ì´ˆ ì´ˆê³¼ ì‹œ ì¤‘ë‹¨)
            if time.time() - start_time > 3:
                logger.warning(f"â° ë§¤ì¹­ íƒ€ì„ì•„ì›ƒ (3ì´ˆ): ë¸Œëœë“œ='{brand}', ìƒí’ˆ='{product[:30]}...' ({processed_count}ê°œ ì²˜ë¦¬ë¨)")
                break
            
            # ë¬´í•œ ë£¨í”„ ë°©ì§€: ì²˜ë¦¬ ê°œìˆ˜ ì œí•œ (20ê°œë¡œ ì œí•œ)
            if processed_count > 20:
                logger.warning(f"ì²˜ë¦¬ ê°œìˆ˜ ì œí•œ (20ê°œ): ë¸Œëœë“œ='{brand}' ({processed_count}ê°œ ì²˜ë¦¬ë¨)")
                break
            
            # ë¸Œëœë“œëŠ” ì´ë¯¸ ì¸ë±ìŠ¤ë¡œ í•„í„°ë§ë¨ (100% ë§¤ì¹­)
            
            # âš¡ ìœ ì‚¬ë„ ê¸°ë°˜ ë§¤ì¹­ ì‹œì‘
            
            # 1. ìƒí’ˆëª… ìœ ì‚¬ë„ ê³„ì‚° (ì •ê·œí™”ëœ ìƒí’ˆëª… ë¹„êµ)
            row_product = self.normalize_product_name(str(row['ìƒí’ˆëª…']).strip())
            product_similarity = self.calculate_similarity(normalized_product, row_product)
            
            # ìƒí’ˆëª… ìœ ì‚¬ë„ê°€ ë„ˆë¬´ ë‚®ìœ¼ë©´ ìŠ¤í‚µ (ë¹ ë¥¸ í•„í„°ë§)
            if product_similarity < 70:
                continue
            
            # âš¡ ì¶”ê°€ í•„í„°ë§: ê¸¸ì´ ë¹„ìœ¨ ì²´í¬ (ì§§ì€ ë‹¨ì–´ì˜ ë¶€ì •í™•í•œ ë§¤ì¹­ ë°©ì§€)
            min_len = min(len(normalized_product), len(row_product))
            max_len = max(len(normalized_product), len(row_product))
            length_ratio = min_len / max_len if max_len > 0 else 0
            
            # ê¸¸ì´ ë¹„ìœ¨ì´ 0.7 ë¯¸ë§Œì´ë©´ ìŠ¤í‚µ (ì˜ˆ: "í‹°" vs "ë°˜íŒ”í‹°" ì œì™¸)
            if length_ratio < 0.7:
                logger.debug(f"ê¸¸ì´ ë¹„ìœ¨ í•„í„°ë§: '{normalized_product}' vs '{row_product}' (ë¹„ìœ¨: {length_ratio:.2f})")
                continue
            
            # 2. ìƒ‰ìƒ ìœ ì‚¬ë„ ê³„ì‚°
            color_similarity = 100.0  # ê¸°ë³¸ê°’ (ìƒ‰ìƒ ì—†ìœ¼ë©´ 100%)
            if color:
                row_color_pattern = self.extract_color(str(row['ì˜µì…˜ì…ë ¥']))
                if row_color_pattern:
                    color_similarity = self.calculate_similarity(color, row_color_pattern)
                else:
                    color_similarity = 0.0  # ìƒ‰ìƒ ì •ë³´ ì—†ìŒ
            
            # 3. ì‚¬ì´ì¦ˆ ìœ ì‚¬ë„ ê³„ì‚°
            size_similarity = 100.0  # ê¸°ë³¸ê°’ (ì‚¬ì´ì¦ˆ ì—†ìœ¼ë©´ 100%)
            if size:
                row_size_pattern = self.extract_size(str(row['ì˜µì…˜ì…ë ¥']))
                if row_size_pattern:
                    size_similarity = self.calculate_similarity(size, row_size_pattern)
                else:
                    size_similarity = 0.0  # ì‚¬ì´ì¦ˆ ì •ë³´ ì—†ìŒ
            
            # 4. ì¢…í•© ìœ ì‚¬ë„ ê³„ì‚° (ê°€ì¤‘ì¹˜ ì ìš©)
            # ë¸Œëœë“œëŠ” ì´ë¯¸ 100%ì´ë¯€ë¡œ ì œì™¸í•˜ê³  ë‚˜ë¨¸ì§€ë§Œ ê³„ì‚°
            total_similarity = (
                product_similarity * 0.5 +   # ìƒí’ˆëª… 50%
                size_similarity * 0.3 +      # ì‚¬ì´ì¦ˆ 30%
                color_similarity * 0.2       # ìƒ‰ìƒ 20%
            )
            
            logger.debug(f"ìœ ì‚¬ë„: ìƒí’ˆ={product_similarity:.1f}%, ì‚¬ì´ì¦ˆ={size_similarity:.1f}%, ìƒ‰ìƒ={color_similarity:.1f}%, ì¢…í•©={total_similarity:.1f}%")
            
            # ì¢…í•© ìœ ì‚¬ë„ê°€ ë„ˆë¬´ ë‚®ìœ¼ë©´ ìŠ¤í‚µ
            if total_similarity < 60:
                continue
            
            # í˜„ì¬ í›„ë³´ ì •ë³´ ì €ì¥
            ê³µê¸‰ê°€ = row['ê³µê¸‰ê°€']
            ì¤‘ë„ë§¤ = row['ì¤‘ë„ë§¤']
            ë¸Œëœë“œìƒí’ˆëª… = f"{row['ë¸Œëœë“œ']} {row['ìƒí’ˆëª…']}"
            
            # âš¡ ì¡°ê¸° ì¢…ë£Œ: 85% ì´ìƒì´ë©´ ì¦‰ì‹œ ë¦¬í„´ (ì¶©ë¶„íˆ ì¢‹ì€ ë§¤ì¹­)
            if total_similarity >= 85:
                logger.debug(f"âœ… ë†’ì€ ìœ ì‚¬ë„ ë§¤ì¹­ ë°œê²¬ ({total_similarity:.1f}%): {ë¸Œëœë“œìƒí’ˆëª…} - ì¦‰ì‹œ ë¦¬í„´!")
                return ê³µê¸‰ê°€, ì¤‘ë„ë§¤, ë¸Œëœë“œìƒí’ˆëª…, True
            
            # ìµœê³  ìœ ì‚¬ë„ ì—…ë°ì´íŠ¸
            if total_similarity > best_similarity:
                best_similarity = total_similarity
                best_match = {
                    'similarity': total_similarity,
                    'ê³µê¸‰ê°€': ê³µê¸‰ê°€,
                    'ì¤‘ë„ë§¤': ì¤‘ë„ë§¤,
                    'ë¸Œëœë“œìƒí’ˆëª…': ë¸Œëœë“œìƒí’ˆëª…,
                    'product_sim': product_similarity,
                    'size_sim': size_similarity,
                    'color_sim': color_similarity
                }
                logger.debug(f"ìµœê³  ìœ ì‚¬ë„ ì—…ë°ì´íŠ¸: {ë¸Œëœë“œìƒí’ˆëª…} ({total_similarity:.1f}%)")

        # ìµœê³  ìœ ì‚¬ë„ ë§¤ì¹­ ê²°ê³¼ ë°˜í™˜
        if best_match and best_similarity >= 60:
            logger.debug(f"âœ… ìµœì¢… ë§¤ì¹­ ì„ íƒ: {best_match['ë¸Œëœë“œìƒí’ˆëª…']} (ìœ ì‚¬ë„: {best_similarity:.1f}%)")
            logger.debug(f"   ìƒì„¸: ìƒí’ˆ={best_match['product_sim']:.1f}%, ì‚¬ì´ì¦ˆ={best_match['size_sim']:.1f}%, ìƒ‰ìƒ={best_match['color_sim']:.1f}%")
            return best_match['ê³µê¸‰ê°€'], best_match['ì¤‘ë„ë§¤'], best_match['ë¸Œëœë“œìƒí’ˆëª…'], True

        logger.debug(f"âŒ ë§¤ì¹­ ì‹¤íŒ¨ (ìµœê³  ìœ ì‚¬ë„: {best_similarity:.1f}% < 60%)")
        return "ë§¤ì¹­ ì‹¤íŒ¨", "", "", False

    def process_matching(self, sheet2_df: pd.DataFrame) -> Tuple[pd.DataFrame, List[Dict]]:
        """Sheet2 ë°ì´í„°ì— ëŒ€í•´ ë§¤ì¹­ ìˆ˜í–‰í•˜ê³  ë§¤ì¹­ ì‹¤íŒ¨í•œ ìƒí’ˆë“¤ ë°˜í™˜"""
        import time
        logger.info("ë§¤ì¹­ ì²˜ë¦¬ ì‹œì‘")

        if sheet2_df.empty:
            logger.warning("ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
            return sheet2_df, []

        success_count = 0
        total_count = len(sheet2_df)
        failed_products = []  # ë§¤ì¹­ ì‹¤íŒ¨í•œ ìƒí’ˆë“¤
        start_time = time.time()
        
        logger.info(f"ì´ {total_count:,}ê°œ í–‰ ì²˜ë¦¬ ì‹œì‘")

        for idx, row in sheet2_df.iterrows():
            # ì§„í–‰ë¥  í‘œì‹œ (10ê°œë§ˆë‹¤ - ë” ìì£¼ ë¡œê¹…)
            current_index = idx + 1 if isinstance(idx, int) else len([i for i in sheet2_df.index if i <= idx])
            if current_index % 10 == 0 or current_index == 1:
                elapsed_time = time.time() - start_time
                progress = (current_index / total_count) * 100
                avg_time = elapsed_time / current_index
                eta = avg_time * (total_count - current_index)
                logger.info(f"ì§„í–‰ë¥ : {current_index:,}/{total_count:,} ({progress:.1f}%) - ê²½ê³¼: {elapsed_time:.1f}ì´ˆ, ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: {eta:.1f}ì´ˆ")
                
                # íƒ€ì„ì•„ì›ƒ ì²´í¬ (10ë¶„ìœ¼ë¡œ ë‹¨ì¶•)
                if elapsed_time > 600:  # 10ë¶„
                    logger.error("ë§¤ì¹­ ì²˜ë¦¬ íƒ€ì„ì•„ì›ƒ (10ë¶„ ì´ˆê³¼) - ì²˜ë¦¬ ì¤‘ë‹¨")
                    break
            
            # ë¸Œëœë“œ, ìƒí’ˆëª…, ì‚¬ì´ì¦ˆ ì¶”ì¶œ
            brand = str(row.get('Hì—´(ë¸Œëœë“œ)', '')).strip()
            product = str(row.get('Iì—´(ìƒí’ˆëª…)', '')).strip()
            size = str(row.get('Kì—´(ì‚¬ì´ì¦ˆ)', '')).strip()
            color = str(row.get('Jì—´(ìƒ‰ìƒ)', '')).strip() # ìƒ‰ìƒ ì¶”ì¶œ
            quantity = row.get('Lì—´(ìˆ˜ëŸ‰)', 1)

            # ë¹ˆ ê°’ ì²´í¬
            if not brand or not product:
                sheet2_df.at[idx, 'Nì—´(ì¤‘ë„ë§¤ëª…)'] = ""
                sheet2_df.at[idx, 'Oì—´(ë„ë§¤ê°€ê²©)'] = 0
                sheet2_df.at[idx, 'Wì—´(ê¸ˆì•¡)'] = 0
                continue

            # ë§¤ì¹­ ìˆ˜í–‰ (íƒ€ì„ì•„ì›ƒ ì ìš©)
            try:
                row_start_time = time.time()
                ê³µê¸‰ê°€, ì¤‘ë„ë§¤, ë¸Œëœë“œìƒí’ˆëª…, success = self.match_row(brand, product, size, color)
                row_elapsed = time.time() - row_start_time
                
                # ë‹¨ì¼ í–‰ ì²˜ë¦¬ê°€ 3ì´ˆë¥¼ ì´ˆê³¼í•˜ë©´ ê²½ê³ 
                if row_elapsed > 3:
                    logger.warning(f"âš ï¸  í–‰ {current_index} ì²˜ë¦¬ ëŠë¦¼: {row_elapsed:.1f}ì´ˆ (ë¸Œëœë“œ: {brand}, ìƒí’ˆ: {product[:30]}...)")
                
                # ë‹¨ì¼ í–‰ ì²˜ë¦¬ê°€ 10ì´ˆë¥¼ ì´ˆê³¼í•˜ë©´ ê°•ì œ ì¤‘ë‹¨
                if row_elapsed > 10:
                    logger.error(f"âŒ í–‰ {current_index} ì²˜ë¦¬ ì‹œê°„ ì´ˆê³¼ (10ì´ˆ): {row_elapsed:.1f}ì´ˆ - ê°•ì œ ì‹¤íŒ¨ ì²˜ë¦¬")
                    ê³µê¸‰ê°€, ì¤‘ë„ë§¤, ë¸Œëœë“œìƒí’ˆëª…, success = "ë§¤ì¹­ ì‹¤íŒ¨", "", "", False
                
            except Exception as e:
                logger.error(f"í–‰ {current_index} ë§¤ì¹­ ì¤‘ ì˜¤ë¥˜: {e} (ë¸Œëœë“œ: {brand}, ìƒí’ˆ: {product})")
                ê³µê¸‰ê°€, ì¤‘ë„ë§¤, ë¸Œëœë“œìƒí’ˆëª…, success = "ë§¤ì¹­ ì‹¤íŒ¨", "", "", False

            # ê²°ê³¼ ì €ì¥
            if success and ê³µê¸‰ê°€ != "ë§¤ì¹­ ì‹¤íŒ¨":
                sheet2_df.at[idx, 'Nì—´(ì¤‘ë„ë§¤ëª…)'] = ì¤‘ë„ë§¤
                sheet2_df.at[idx, 'Oì—´(ë„ë§¤ê°€ê²©)'] = ê³µê¸‰ê°€
                # Wì—´ ê¸ˆì•¡ ê³„ì‚°: ë„ë§¤ê°€ê²© Ã— ìˆ˜ëŸ‰
                try:
                    total_amount = float(ê³µê¸‰ê°€) * int(quantity)
                    sheet2_df.at[idx, 'Wì—´(ê¸ˆì•¡)'] = total_amount
                except:
                    sheet2_df.at[idx, 'Wì—´(ê¸ˆì•¡)'] = 0
                success_count += 1
            else:
                # ë§¤ì¹­ ì‹¤íŒ¨í•œ ìƒí’ˆ ì •ë³´ ìˆ˜ì§‘
                failed_product = {
                    'ë¸Œëœë“œ': brand,
                    'ìƒí’ˆëª…': product,
                    'ìƒ‰ìƒ': color,
                    'ì‚¬ì´ì¦ˆ': size,
                    'ìˆ˜ëŸ‰': quantity,
                    'í–‰ë²ˆí˜¸': idx
                }
                
                # ì›ë³¸ í–‰ì˜ ëª¨ë“  ë°ì´í„° ì¶”ê°€
                for col_name, col_value in row.items():
                    if col_name not in failed_product:
                        failed_product[col_name] = col_value
                
                failed_products.append(failed_product)
                
                sheet2_df.at[idx, 'Nì—´(ì¤‘ë„ë§¤ëª…)'] = ""
                sheet2_df.at[idx, 'Oì—´(ë„ë§¤ê°€ê²©)'] = 0
                sheet2_df.at[idx, 'Wì—´(ê¸ˆì•¡)'] = 0

        total_elapsed = time.time() - start_time
        success_rate = (success_count / total_count * 100) if total_count > 0 else 0
        logger.info(f"ë§¤ì¹­ ì™„ë£Œ: {success_count:,}/{total_count:,} ({success_rate:.1f}%) - ì´ ì†Œìš”ì‹œê°„: {total_elapsed:.1f}ì´ˆ")
        logger.info(f"ë§¤ì¹­ ì‹¤íŒ¨: {len(failed_products):,}ê°œ ìƒí’ˆ")

        return sheet2_df, failed_products

    def process_matching_with_similarity(self, sheet2_df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:
        """ë§¤ì¹­ ìˆ˜í–‰ í›„ ì‹¤íŒ¨í•œ ìƒí’ˆë“¤ì— ëŒ€í•´ ìœ ì‚¬ë„ ë§¤ì¹­ ì¶”ê°€ ìˆ˜í–‰"""
        logger.info("ì •í™• ë§¤ì¹­ + ìœ ì‚¬ë„ ë§¤ì¹­ ì²˜ë¦¬ ì‹œì‘")
        
        # 1ë‹¨ê³„: ì •í™• ë§¤ì¹­
        matched_df, failed_products = self.process_matching(sheet2_df)
        
        # 2ë‹¨ê³„: ë§¤ì¹­ ì‹¤íŒ¨í•œ ìƒí’ˆë“¤ì— ëŒ€í•´ ìœ ì‚¬ë„ ë§¤ì¹­
        similarity_results_df = pd.DataFrame()
        if failed_products:
            logger.info(f"ë§¤ì¹­ ì‹¤íŒ¨í•œ {len(failed_products)}ê°œ ìƒí’ˆì— ëŒ€í•´ ìœ ì‚¬ë„ ë§¤ì¹­ ì‹œì‘")
            similarity_results_df = self.find_similar_products_for_failed_matches(failed_products)
        
        return matched_df, similarity_results_df

    def save_to_excel(self, sheet2_df: pd.DataFrame, filename: str = "ë¸Œëœë“œë§¤ì¹­ê²°ê³¼.xlsx"):
        """Sheet2 í˜•ì‹ìœ¼ë¡œ ì—‘ì…€ íŒŒì¼ ì €ì¥"""
        try:
            with pd.ExcelWriter(filename, engine='openpyxl') as writer:
                # Sheet2 íƒ­ì— ì €ì¥
                sheet2_df.to_excel(writer, sheet_name='Sheet2', index=False)

                # ì»¬ëŸ¼ ë„ˆë¹„ ì¡°ì •
                worksheet = writer.sheets['Sheet2']
                for i, column in enumerate(sheet2_df.columns, 1):
                    if i <= 26:
                        column_letter = chr(64 + i)
                    else:
                        column_letter = f"A{chr(64 + i - 26)}"
                    worksheet.column_dimensions[column_letter].width = 15

            logger.info(f"ì—‘ì…€ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {filename}")
            return filename

        except Exception as e:
            logger.error(f"ì—‘ì…€ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")
            raise e

    def save_similarity_results_to_excel(self, similarity_df: pd.DataFrame, filename: str = "ìœ ì‚¬ë„ë§¤ì¹­ê²°ê³¼.xlsx"):
        """ìœ ì‚¬ë„ ë§¤ì¹­ ê²°ê³¼ë¥¼ ì—‘ì…€ íŒŒì¼ë¡œ ì €ì¥"""
        try:
            with pd.ExcelWriter(filename, engine='openpyxl') as writer:
                # ìœ ì‚¬ë„ ë§¤ì¹­ ê²°ê³¼ ì €ì¥
                similarity_df.to_excel(writer, sheet_name='ìœ ì‚¬ë„ë§¤ì¹­ê²°ê³¼', index=False)

                # ì»¬ëŸ¼ ë„ˆë¹„ ì¡°ì •
                worksheet = writer.sheets['ìœ ì‚¬ë„ë§¤ì¹­ê²°ê³¼']
                for i, column in enumerate(similarity_df.columns, 1):
                    column_letter = self._get_column_letter(i)
                    
                    # ì»¬ëŸ¼ëª…ì— ë”°ë¥¸ ë„ˆë¹„ ì¡°ì •
                    if 'ìƒí’ˆëª…' in column:
                        worksheet.column_dimensions[column_letter].width = 30
                    elif 'ìœ ì‚¬ë„' in column:
                        worksheet.column_dimensions[column_letter].width = 12
                    elif 'ë¸Œëœë“œ' in column:
                        worksheet.column_dimensions[column_letter].width = 15
                    elif 'ìƒ‰ìƒ' in column or 'ì‚¬ì´ì¦ˆ' in column:
                        worksheet.column_dimensions[column_letter].width = 15
                    elif 'ì¤‘ë„ë§¤' in column or 'ê³µê¸‰ê°€' in column:
                        worksheet.column_dimensions[column_letter].width = 12
                    else:
                        worksheet.column_dimensions[column_letter].width = 15

                # í—¤ë” ìŠ¤íƒ€ì¼ ì ìš©
                from openpyxl.styles import Font, PatternFill, Alignment
                header_font = Font(bold=True, color="FFFFFF")
                header_fill = PatternFill(start_color="366092", end_color="366092", fill_type="solid")
                
                for cell in worksheet[1]:
                    cell.font = header_font
                    cell.fill = header_fill
                    cell.alignment = Alignment(horizontal="center")

                # ìœ ì‚¬ë„ ì»¬ëŸ¼ì— ì¡°ê±´ë¶€ ì„œì‹ ì ìš©
                for col_idx, column in enumerate(similarity_df.columns, 1):
                    if 'ìœ ì‚¬ë„' in column:
                        column_letter = self._get_column_letter(col_idx)
                        for row_idx in range(2, len(similarity_df) + 2):
                            cell = worksheet[f"{column_letter}{row_idx}"]
                            try:
                                value = float(cell.value)
                                if value >= 0.8:
                                    cell.fill = PatternFill(start_color="C6EFCE", end_color="C6EFCE", fill_type="solid")
                                elif value >= 0.6:
                                    cell.fill = PatternFill(start_color="FFEB9C", end_color="FFEB9C", fill_type="solid")
                                elif value >= 0.3:
                                    cell.fill = PatternFill(start_color="FFC7CE", end_color="FFC7CE", fill_type="solid")
                            except:
                                pass

            logger.info(f"ìœ ì‚¬ë„ ë§¤ì¹­ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {filename}")
            return filename

        except Exception as e:
            logger.error(f"ìœ ì‚¬ë„ ë§¤ì¹­ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")
            raise e

    def _get_column_letter(self, col_idx: int) -> str:
        """ì»¬ëŸ¼ ì¸ë±ìŠ¤ë¥¼ ì—‘ì…€ ì»¬ëŸ¼ ë¬¸ìë¡œ ë³€í™˜"""
        result = ""
        while col_idx > 0:
            col_idx -= 1
            result = chr(col_idx % 26 + ord('A')) + result
            col_idx //= 26
        return result 